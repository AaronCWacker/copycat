\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{listings}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\definecolor{lightgrey}{rgb}{0.9, 0.9, 0.9}
\lstset{ %
    backgroundcolor=\color{lightgrey}}

\title{Distributed Behavior in a Fluid Analogy Architecture}
\author{Lucas Saldyt, Alexandre Linhares}

\begin{document}
\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}

    This paper stems from Mitchell's (1993) and Hofstadter's \& FARG's (1995) work on the copycat program. 
    This project focuses on effectively simulating intelligent processes through increasingly distributed decision-making.
    In the process of evaluating the distributed nature of copycat, this paper also proposes a "Normal Science" framework. 

    First, copycat uses a "Parallel Terraced Scan" as a humanistic inspired search algorithm.
    The Parallel Terraced Scan corresponds to the psychologically-plausible behavior of briefly browsing, say, a book, and delving deeper whenever something sparks one's interest. 
    In a way, it is a mix between a depth-first and breadth-first search.
    This type of behavior seems to very fluidly change the intensity of an activity based on local, contextual cues. 
    Previous FARG models use centralized structures, like the global temperature value, to control the behavior of the Parallel Terraced Scan.
    This paper explores how to maintain the same behavior while distributing decision-making throughout the system.

    Specifically, this paper attempts different refactors of the copycat architecture.
    First, the probability adjustment formulas based on temperature are changed.
    Then, we experiment with two methods for replacing temperature with a distributed metric.
    Initially, temperature is removed destructively, essentially removing any lines of code that mention it, simply to see what effect it has.
    Then, a surgical removal of temperature is attempted, leaving in tact affected structures or replacing them by effective distributed mechanisms.

    To evaluate the distributed nature of copycat, this paper focuses on the creation of a `normal science' framework.
    By `Normal science,' this paper means the term created by Thomas Kuhn--the collaborative enterprise of furthering understanding within a paradigm. 
    Today, "normal science" is simply not done on FARG architectures (and on most computational cognitive architectures too... see Addyman \& French 2012). 
    Unlike mathematical theories or experiments, which can be replicated by following the materials and methods, computational models generally have dozens of particularly tuned variables, undocumented procedures, multiple assumptions about the users computational environment, etc.
    It then becomes close to impossible to reproduce a result, or to test some new idea scientifically. 
    This paper focuses on the introduction of statistical techniques, reduction of "magic numbers", improvement and documentation of formulas, and proposals for statistical human comparison.

    We also discuss, in general, the nature of the brain as a distributed system.
    While the removal of a single global variable may initially seem trivial, one must realize that copycat and other cognitive architectures have many central structures.
    This paper explores the justification of these central structures in general.
    Is it possible to model intelligence with them, or are they harmful?

%% {Von Neumann Discussion}
%% {Turing Completeness}
%% {Simulation of Distributed Processes}
%% {Efficiency of True Distribution}
%% {Temperature in Copycat}
%% {Other Centralizers in Copycat}
%% {The Motivation for Removing Centralizers in Copycat}

\section{Methods}
    \subsection{Formula Documentation}
    \subsection{Testing the Effect of Temperature}
    \subsection{Temperature Probability Adjustment}
    \subsection{Temperature Usage Adjustment}
    \subsection{$\chi^2$ Distribution Testing}
\section{Results}
    \subsection{Cross $\chi^2$ Table}
\section{Discussion}
    \subsection{Distributed Computation Accuracy}
    \subsection{Prediction}

\bibliographystyle{alpha}
\bibliography{sample}

\end{document}
